{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49339d5-8189-4628-bdae-2010749967d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 03m 04s]\n",
      "val_loss: 0.6924039125442505\n",
      "\n",
      "Best val_loss So Far: 0.6473692655563354\n",
      "Total elapsed time: 00h 03m 54s\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 2.0009 - accuracy: 0.5172\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.6793 - accuracy: 0.5586\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.6127 - accuracy: 0.6621\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.5396 - accuracy: 0.7828\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.4169 - accuracy: 0.8276\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x74869c861f10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image as IPImage, display  # for displaying images in Jupyter\n",
    "\n",
    "\n",
    "# File paths for the Fake and Real image directories\n",
    "fake_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/fake_images/'\n",
    "real_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/real_images/'\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_data(fake_dir, real_dir, img_size=(128, 128)):\n",
    "    images = []\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    # Fake images\n",
    "    for img_name in os.listdir(fake_dir):\n",
    "        if img_name.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            img_path = os.path.join(fake_dir, img_name)\n",
    "            img = image.load_img(img_path, target_size=img_size)\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255.0  # Normalize the images\n",
    "            images.append(img)\n",
    "            labels.append(0)  # Fake = 0\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "    # Real images\n",
    "    for img_name in os.listdir(real_dir):\n",
    "        if img_name.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            img_path = os.path.join(real_dir, img_name)\n",
    "            img = image.load_img(img_path, target_size=img_size)\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255.0  # Normalize the images\n",
    "            images.append(img)\n",
    "            labels.append(1)  # Real = 1\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, image_paths\n",
    "\n",
    "# Load and prepare the data\n",
    "x_data, y_data, image_paths = prepare_data(fake_dir, real_dir)\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "x_train, x_test, y_train, y_test, image_paths_train, image_paths_test = train_test_split(x_data, y_data, image_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the AutoKeras ImageClassifier\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=3)  # max_trials sets the number of models to try\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(x_train, y_train, epochs=5) # Increase epochs to train longer if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16445d41-e47b-47c3-bc2d-f56b4a3f8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5954 - accuracy: 0.6849\n",
      "Test accuracy: 0.6849315166473389\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7486251261f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7486251261f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5954 - accuracy: 0.6849\n",
      "Test Accuracy: 0.685\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 18ms/step\n",
      "Predicted labels: [0. 1. 0. 0. 0.]\n",
      "True labels: [0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "test_loss, test_acc = clf.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = clf.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Predict with the best model\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f\"Predicted labels: {y_pred[:5].flatten()}\")\n",
    "print(f\"True labels: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad05dc5-e15d-4fe2-a8f3-0f3dd500debe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " cast_to_float32 (CastToFlo  (None, 128, 128, 3)       0         \n",
      " at32)                                                           \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 128, 128, 3)       7         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 62, 62, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 246016)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 246017    \n",
      "                                                                 \n",
      " classification_head_1 (Act  (None, 1)                 0         \n",
      " ivation)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265416 (1.01 MB)\n",
      "Trainable params: 265409 (1.01 MB)\n",
      "Non-trainable params: 7 (32.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model=clf.export_model()\n",
    "keras_model.summary()\n",
    "\n",
    "\n",
    "# Evaluate save file\n",
    "#predictor.save("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7aaf9e-716e-4b53-84a9-1c0939a7292e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6849\n",
      "Precision: 0.7143\n",
      "Recall: 0.4688\n",
      "F1 Score: 0.5660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4084e1b7-b936-4f67-85fd-a0df9731a66a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Take one image from the test data, show it, and display the label and prediction\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sample_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m984\u001b[39m \u001b[38;5;66;03m# You can change this index to display a different image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m sample_image_path \u001b[38;5;241m=\u001b[39m \u001b[43mimage_paths_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m true_label \u001b[38;5;241m=\u001b[39m y_test[sample_index]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert predicted_label to a scalar if it's a numpy array\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Take one image from the test data, show it, and display the label and prediction\n",
    "sample_index = 984 # You can change this index to display a different image\n",
    "\n",
    "sample_image_path = image_paths_test[sample_index]\n",
    "true_label = y_test[sample_index]\n",
    "\n",
    "# Convert predicted_label to a scalar if it's a numpy array\n",
    "predicted_label = y_pred[sample_index]\n",
    "if isinstance(predicted_label, np.ndarray):\n",
    "    predicted_label = predicted_label.item()\n",
    "\n",
    "# Convert label numbers to human-readable labels\n",
    "label_map = {0: 'Fake', 1: 'Real'}\n",
    "true_label_text = label_map[true_label]\n",
    "predicted_label_text = label_map[predicted_label]\n",
    "\n",
    "# Display the image\n",
    "display(IPImage(filename=sample_image_path))\n",
    "\n",
    "# Print the true label and predicted label\n",
    "print(f\"True Label: {true_label_text}\")\n",
    "print(f\"Predicted Label: {predicted_label_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a715ac-25d4-47bf-b06c-8375eb63529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 17:41:45.118597: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-04 17:41:45.139475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 17:41:45.445546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2651109-7c3d-4709-a18f-6c9972003952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autokeras in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (1.0.20)\n",
      "Requirement already satisfied: packaging in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from autokeras) (24.1)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from autokeras) (2.12.0)\n",
      "Requirement already satisfied: keras-tuner>=1.1.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from autokeras) (1.4.7)\n",
      "Requirement already satisfied: pandas in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from autokeras) (2.2.2)\n",
      "Requirement already satisfied: keras in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (2.12.0)\n",
      "Requirement already satisfied: requests in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (1.0.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.66.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (3.11.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (18.1.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (4.25.4)\n",
      "Requirement already satisfied: setuptools in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from pandas->autokeras) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from pandas->autokeras) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from pandas->autokeras) (2024.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.43.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow>=2.8.0->autokeras) (7.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2024.7.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow>=2.8.0->autokeras) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.8.0->autokeras) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88715b2a-60d7-45b2-be1e-f71d41dab465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-10.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d90a256-af59-464e-a1fd-da196486090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT is available in TensorFlow.\n",
      "<module 'tensorflow.python.compiler.tensorrt.trt_convert' from '/home/michael/miniconda3/envs/autoKeras/lib/python3.9/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert\n",
    "\n",
    "try:\n",
    "    print(\"TensorRT is available in TensorFlow.\")\n",
    "    print(trt_convert)\n",
    "except ImportError:\n",
    "    print(\"TensorRT is not available in TensorFlow.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef0293fc-f533-4253-9785-117fce6bde50",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expect the data to TextInput to be numpy.ndarray or tf.data.Dataset, but got <class 'pandas.core.series.Series'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 84\u001b[0m\n\u001b[1;32m     76\u001b[0m model \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mAutoModel(\n\u001b[1;32m     77\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[input_image, input_text],\n\u001b[1;32m     78\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutput,\n\u001b[1;32m     79\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_image_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_text_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_image_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can use the same labels for both modalities\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     88\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     91\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([x_image_test, x_text_test], y_image_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/autokeras/auto_model.py:280\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data:\n\u001b[1;32m    278\u001b[0m     validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 280\u001b[0m dataset, validation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analyze_data(dataset)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hyper_pipeline(dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/autokeras/auto_model.py:398\u001b[0m, in \u001b[0;36mAutoModel._convert_to_dataset\u001b[0;34m(self, x, y, validation_data, batch_size)\u001b[0m\n\u001b[1;32m    396\u001b[0m     x \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x)\n\u001b[1;32m    397\u001b[0m     y \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: y)\n\u001b[0;32m--> 398\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapt(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_heads, batch_size)\n\u001b[1;32m    400\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((x, y))\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/autokeras/auto_model.py:311\u001b[0m, in \u001b[0;36mAutoModel._adapt\u001b[0;34m(self, dataset, hms, batch_size)\u001b[0m\n\u001b[1;32m    309\u001b[0m adapted \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source, hm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sources, hms):\n\u001b[0;32m--> 311\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mhm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     adapted\u001b[38;5;241m.\u001b[39mappend(source)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapted) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/autokeras/engine/adapter.py:67\u001b[0m, in \u001b[0;36mAdapter.adapt\u001b[0;34m(self, dataset, batch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madapt\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, batch_size):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check, convert and batch the dataset.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        tf.data.Dataset. The converted dataset.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_dataset(dataset, batch_size)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/autokeras/adapters/input_adapters.py:56\u001b[0m, in \u001b[0;36mTextAdapter.check\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Record any information needed by transform.\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (np\u001b[38;5;241m.\u001b[39mndarray, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset)):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect the data to TextInput to be numpy.ndarray or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.data.Dataset, but got \u001b[39m\u001b[38;5;132;01m{type}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[1;32m     59\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expect the data to TextInput to be numpy.ndarray or tf.data.Dataset, but got <class 'pandas.core.series.Series'>."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# File paths for the Fake and Real image directories\n",
    "fake_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/fake_images/'\n",
    "real_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/real_images/'\n",
    "file_path = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/train_posts_twitter.csv'\n",
    "\n",
    "# Prepare image data\n",
    "def prepare_data(fake_dir, real_dir, img_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Fake images\n",
    "    for img_name in os.listdir(fake_dir):\n",
    "        if img_name.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            img_path = os.path.join(fake_dir, img_name)\n",
    "            img = image.load_img(img_path, target_size=img_size)\n",
    "            img = image.img_to_array(img) / 255.0  # Normalize images\n",
    "            images.append(img)\n",
    "            labels.append(0)  # Fake = 0\n",
    "\n",
    "    # Real images\n",
    "    for img_name in os.listdir(real_dir):\n",
    "        if img_name.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            img_path = os.path.join(real_dir, img_name)\n",
    "            img = image.load_img(img_path, target_size=img_size)\n",
    "            img = image.img_to_array(img) / 255.0  # Normalize images\n",
    "            images.append(img)\n",
    "            labels.append(1)  # Real = 1\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Load the image data\n",
    "x_image_data, y_image_labels = prepare_data(fake_dir, real_dir)\n",
    "\n",
    "# Prepare the text data\n",
    "df = pd.read_csv(file_path)\n",
    "df_expanded = df.assign(image_id=df['image_id(s)'].astype(str).str.split(','))\n",
    "df_expanded = df_expanded.explode('image_id').reset_index(drop=True)\n",
    "\n",
    "# Create text and image ID mapping\n",
    "text_data = df_expanded['post_text']\n",
    "image_ids = df_expanded['image_id']\n",
    "text_labels = df_expanded['label']  # Assuming the label column exists and contains 0 for \"fake\" and 1 for \"real\"\n",
    "\n",
    "# Convert text labels to categorical\n",
    "text_labels = np.array(text_labels)\n",
    "\n",
    "# Split both text and image data into train/test sets\n",
    "x_image_train, x_image_test, y_image_train, y_image_test = train_test_split(\n",
    "    x_image_data, y_image_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "x_text_train, x_text_test, y_text_train, y_text_test = train_test_split(\n",
    "    text_data, text_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the AutoKeras multimodal model\n",
    "input_image = ak.ImageInput()\n",
    "input_text = ak.TextInput()\n",
    "\n",
    "# Combine the two inputs\n",
    "merged_output = ak.Merge()([input_image, input_text])\n",
    "output = ak.ClassificationHead()(merged_output)\n",
    "\n",
    "# Build the AutoKeras model\n",
    "model = ak.AutoModel(\n",
    "    inputs=[input_image, input_text],\n",
    "    outputs=output,\n",
    "    overwrite=True,\n",
    "    max_trials=5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    [x_image_train, x_text_train],\n",
    "    y_image_train,  # You can use the same labels for both modalities\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([x_image_test, x_text_test], y_image_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1665c74-3ed3-4dae-a305-f6ca8916a178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 10s]\n",
      "val_loss: 0.011727719567716122\n",
      "\n",
      "Best val_loss So Far: 0.011041399091482162\n",
      "Total elapsed time: 00h 00m 53s\n",
      "Epoch 1/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.9338\n",
      "Epoch 2/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9934\n",
      "Epoch 4/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 5/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 4.0994e-04 - accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9954\n",
      "Test Accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# File paths\n",
    "fake_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/fake_images/'\n",
    "real_dir = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/images_train/real_images/'\n",
    "file_path = '/home/michael/Documenti/Milinda_Githubproject/Weibo and Twitter/twitter/Rearranged_Train_Posts_Single_ImageID.csv'\n",
    "\n",
    "# Helper function to load and preprocess image data\n",
    "def load_images(image_dir, img_size=(128, 128)):\n",
    "    image_dict = {}\n",
    "    for img_name in os.listdir(image_dir):\n",
    "        if img_name.endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            # Remove the file extension to get image_id\n",
    "            image_id = os.path.splitext(img_name)[0]\n",
    "            img_path = os.path.join(image_dir, img_name)\n",
    "            img = image.load_img(img_path, target_size=img_size)\n",
    "            img_array = image.img_to_array(img) / 255.0  # Normalize images\n",
    "            image_dict[image_id] = img_array\n",
    "    return image_dict\n",
    "\n",
    "# Load image data\n",
    "fake_images = load_images(fake_dir)\n",
    "real_images = load_images(real_dir)\n",
    "\n",
    "# Combine fake and real images\n",
    "all_images = {**fake_images, **real_images}\n",
    "\n",
    "# Load and preprocess the text data\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows with null `image_id` or those that don't have a matching image\n",
    "df = df.dropna(subset=['image_id'])\n",
    "df['image_id'] = df['image_id'].astype(str)  # Ensure image_id is string for matching\n",
    "df = df[df['image_id'].isin(all_images.keys())]\n",
    "\n",
    "# Extract the matched images and labels\n",
    "image_data = np.array([all_images[img_id] for img_id in df['image_id']])\n",
    "text_data = df['post_text'].tolist()  # Leave as a list for AutoKeras tokenization\n",
    "labels = df['label'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_image_train, x_image_test, x_text_train, x_text_test, y_train, y_test = train_test_split(\n",
    "    image_data, text_data, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure text data is passed as a NumPy array of strings\n",
    "x_text_train = np.array(x_text_train, dtype=str)\n",
    "x_text_test = np.array(x_text_test, dtype=str)\n",
    "\n",
    "# Create the AutoKeras multimodal model\n",
    "input_image = ak.ImageInput()\n",
    "input_text = ak.TextInput()\n",
    "\n",
    "# Add preprocessing for the text input\n",
    "preprocessed_text = ak.TextToNgramVector()(input_text)  # Tokenize and vectorize text\n",
    "merged_output = ak.Merge()([input_image, preprocessed_text])\n",
    "output = ak.ClassificationHead()(merged_output)\n",
    "\n",
    "# Build the AutoKeras model\n",
    "model = ak.AutoModel(\n",
    "    inputs=[input_image, input_text],\n",
    "    outputs=output,\n",
    "    overwrite=True,\n",
    "    max_trials=5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    [x_image_train, x_text_train],\n",
    "    y_train,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the classifier\n",
    "test_loss, test_acc = model.evaluate([x_image_test, x_text_test], y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80a5cc6-cb75-4c0c-82e7-ffd5213211c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step\n",
      "75/75 [==============================] - 0s 2ms/step\n",
      "Predicted labels: [0 0 0 0 0]\n",
      "True labels: ['real' 'real' 'fake' 'real' 'real']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Predict with the best model\n",
    "y_pred = model.predict([x_image_test, x_text_test])\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Convert predictions to class labels\n",
    "\n",
    "print(f\"Predicted labels: {y_pred_labels[:5].flatten()}\")\n",
    "print(f\"True labels: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36f6db11-91e4-45d2-9731-0cd18df4782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " cast_to_float32 (CastToFlo  (None, 128, 128, 3)          0         ['input_1[0][0]']             \n",
      " at32)                                                                                            \n",
      "                                                                                                  \n",
      " expand_last_dim (ExpandLas  (None, 1)                    0         ['input_2[0][0]']             \n",
      " tDim)                                                                                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 49152)                0         ['cast_to_float32[0][0]']     \n",
      "                                                                                                  \n",
      " text_vectorization (TextVe  (None, 20000)                1         ['expand_last_dim[0][0]']     \n",
      " ctorization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 69152)                0         ['flatten[0][0]',             \n",
      "                                                                     'text_vectorization[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    69153     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " classification_head_1 (Act  (None, 1)                    0         ['dense[0][0]']               \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69154 (270.14 KB)\n",
      "Trainable params: 69153 (270.13 KB)\n",
      "Non-trainable params: 1 (8.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Accuracy: 0.5821\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/miniconda3/envs/autoML/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/michael/miniconda3/envs/autoML/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf.Variable 'Variable:0' shape=(None,) dtype=float32, numpy=\narray([7.7119904, 0.884729 , 1.73271  , ..., 8.473241 , 8.473241 ,\n       8.473241 ], dtype=float32)>, <keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x74866eb8cd60>, <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Optionally save the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_autokeras_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_autokeras_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/autoML/lib/python3.8/site-packages/keras/src/saving/legacy/hdf5_format.py:1110\u001b[0m, in \u001b[0;36m_legacy_weights\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m   1108\u001b[0m weights \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m layer\u001b[38;5;241m.\u001b[39mnon_trainable_weights\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, tf\u001b[38;5;241m.\u001b[39mVariable) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSave or restore weights that is not an instance of `tf.Variable` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not supported in h5, use `save_format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` instead. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma model or layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith weights \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m     )\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf.Variable 'Variable:0' shape=(None,) dtype=float32, numpy=\narray([7.7119904, 0.884729 , 1.73271  , ..., 8.473241 , 8.473241 ,\n       8.473241 ], dtype=float32)>, <keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x74866eb8cd60>, <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=0>]"
     ]
    }
   ],
   "source": [
    "# Export the best model and print its summary\n",
    "keras_model = model.export_model()\n",
    "keras_model.summary()\n",
    "# Define the mapping between numeric labels and string labels\n",
    "label_mapping = {0: 'fake', 1: 'real'}\n",
    "\n",
    "# Map numeric predictions back to string labels\n",
    "y_pred_mapped = np.array([label_mapping[pred] for pred in y_pred_labels])\n",
    "\n",
    "# Ensure y_test is a NumPy array for consistency\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Evaluate using sklearn metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_mapped)\n",
    "precision = precision_score(y_test, y_pred_mapped, pos_label='real')\n",
    "recall = recall_score(y_test, y_pred_mapped, pos_label='real')\n",
    "f1 = f1_score(y_test, y_pred_mapped, pos_label='real')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Optionally save the model\n",
    "keras_model.save(\"best_autokeras_model.h5\")\n",
    "print(\"Best model saved as 'best_autokeras_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2eb561-53a8-4c71-b6b4-ba9eb2b66871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
